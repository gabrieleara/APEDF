From 2bda5d569a2a546a3c9e9e41d1ebece54f5717a7 Mon Sep 17 00:00:00 2001
From: Gabriele Ara <gabriele.ara@santannapisa.it>
Date: Wed, 16 Nov 2022 13:16:06 +0100
Subject: Changes for experimentations on ODROID board

---
 kernel/sched/cpufreq_schedutil.c | 25 +++++++++++++++++++++++++
 1 file changed, 25 insertions(+)

diff --git a/kernel/sched/cpufreq_schedutil.c b/kernel/sched/cpufreq_schedutil.c
index 831fee509..64b9f16bc 100644
--- a/kernel/sched/cpufreq_schedutil.c
+++ b/kernel/sched/cpufreq_schedutil.c
@@ -173,6 +173,10 @@ static unsigned int get_next_freq(struct sugov_policy *sg_policy,
 	unsigned int freq = arch_scale_freq_invariant() ?
 				policy->cpuinfo.max_freq : policy->cur;
 
+	/* Only for our tests for SCHED_DEADLINE in a controlled environment! */
+	if (freq > 1400000)
+		freq = 1400000;
+
 	freq = map_util_freq(util, freq, max);
 
 	if (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)
@@ -210,10 +214,25 @@ unsigned long schedutil_cpu_util(int cpu, unsigned long util_cfs,
 	unsigned long dl_util, util, irq;
 	struct rq *rq = cpu_rq(cpu);
 
+	/*
+	 * Throughout this function I commented some code
+	 * that might pollute our tests on the
+	 * energy-savings of our patches to DEADLINE.
+	 * During our tests, we don't give a damn about
+	 * lower-priority tasks, so long as the kernel does
+	 * not panic we are good.
+	 *
+	 * If you see some code commented out, remember that
+	 * it should NOT be commented out in any real
+	 * environment outside those tests.
+	 */
+
+	/*
 	if (!uclamp_is_used() &&
 	    type == FREQUENCY_UTIL && rt_rq_is_runnable(&rq->rt)) {
 		return max;
 	}
+	*/
 
 	/*
 	 * Early check to see if IRQ/steal time saturates the CPU, can be
@@ -236,9 +255,11 @@ unsigned long schedutil_cpu_util(int cpu, unsigned long util_cfs,
 	 * When there are no CFS RUNNABLE tasks, clamps are released and
 	 * frequency will be gracefully reduced with the utilization decay.
 	 */
+	/*
 	util = util_cfs + cpu_util_rt(rq);
 	if (type == FREQUENCY_UTIL)
 		util = uclamp_util_with(rq, util, p);
+	*/
 
 	dl_util = cpu_util_dl(rq);
 
@@ -537,6 +558,10 @@ sugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)
 	if (sugov_should_update_freq(sg_policy, time)) {
 		next_f = sugov_next_freq_shared(sg_cpu, time);
 
+		/* Only for our tests in a controlled environment */
+		if (next_f > 1400000)
+			next_f = 1400000;
+
 		if (sg_policy->policy->fast_switch_enabled)
 			sugov_fast_switch(sg_policy, time, next_f);
 		else
-- 
2.38.1

